{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qkcVt5JtH92H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_star(n_spikes=5, inner_radius=0.4, outer_radius=1.0, n_samples=1000, center=(0, 0)):\n",
        "    points = []\n",
        "    angle_step = np.pi / n_spikes\n",
        "\n",
        "    # Generate the star's vertices\n",
        "    vertices = []\n",
        "    for i in range(2 * n_spikes):\n",
        "        angle = i * angle_step\n",
        "        radius = outer_radius if i % 2 == 0 else inner_radius\n",
        "\n",
        "        x = radius * np.cos(angle) + center[0]\n",
        "        y = radius * np.sin(angle) + center[1]\n",
        "        vertices.append([x, y])\n",
        "    vertices.append(vertices[0])\n",
        "\n",
        "    # Sample points along the star's edges\n",
        "    vertices = np.array(vertices)\n",
        "    sampled_points = []\n",
        "\n",
        "    for i in range(len(vertices) - 1):\n",
        "        start_point = vertices[i]\n",
        "        end_point = vertices[i + 1]\n",
        "\n",
        "        # Interpolate points along the edge\n",
        "        for t in np.linspace(0, 1, n_samples // (len(vertices) - 1)):\n",
        "            point = (1 - t) * start_point + t * end_point\n",
        "            sampled_points.append(point)\n",
        "\n",
        "    return np.array(sampled_points)"
      ],
      "metadata": {
        "id": "JS1eq_uDWJ3B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star = generate_star(n_samples=5000)"
      ],
      "metadata": {
        "id": "IRV7w7-HWLEm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return betas, alphas_cumprod"
      ],
      "metadata": {
        "id": "1W4nF-t8WMrR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q_sample(x_0, t, alphas_cumprod, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_0)\n",
        "\n",
        "    alphas_cumprod_t = alphas_cumprod[t].view(-1, 1)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod_t)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod_t)\n",
        "\n",
        "    return sqrt_alphas_cumprod * x_0 + sqrt_one_minus_alphas_cumprod * noise"
      ],
      "metadata": {
        "id": "5HhnG931WiZF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyUNet2D(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2 + hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t = t.float()\n",
        "        t_embed = self.time_embed(t.view(-1, 1))\n",
        "        # [B, 1] --> [B, H]\n",
        "        # x: [B, 2] + [B, H] -- > [B, H + 2] -- > [B, 2]\n",
        "        x_input = torch.cat([x, t_embed], dim=1)\n",
        "\n",
        "        return self.net(x_input)"
      ],
      "metadata": {
        "id": "tuszmpvgWlYc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "XH9l8E2QRa1t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "star = generate_star(n_samples=5000)\n",
        "dataset = TensorDataset(torch.tensor(star, dtype=torch.float32))\n",
        "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "model = TinyUNet2D(256).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 2500\n",
        "timesteps = 1000\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  model.train()\n",
        "  total_loss = 0.\n",
        "\n",
        "  for batch in dataloader:\n",
        "    batch = batch[0].to(device)\n",
        "    # [B, 2]            | -- > cat([B,2 ], [B, H]) --> [B, H+2] -- > [B, H]\n",
        "    # [B, 1] --> [B, H] |\n",
        "    t = torch.randint(0, timesteps, (batch.size(0),), device=device)\n",
        "\n",
        "    _, alphas_cumprod = cosine_beta_schedule(timesteps)\n",
        "    alphas_cumprod = alphas_cumprod.to(device)\n",
        "\n",
        "    noise = torch.randn_like(batch)\n",
        "    x_t = q_sample(batch, t, alphas_cumprod, noise)\n",
        "\n",
        "    pred_noise = model(x_t, t)\n",
        "\n",
        "    loss = F.mse_loss(pred_noise, noise)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch: {epoch} Train Loss: {total_loss / len(dataloader)}\")"
      ],
      "metadata": {
        "id": "uc86nk5hWwuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05972efd-91bb-4bcb-dc5a-58d4b3316f5a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 Train Loss: 0.7969829320907593\n",
            "Epoch: 200 Train Loss: 0.38335553407669065\n",
            "Epoch: 300 Train Loss: 0.3621167317032814\n",
            "Epoch: 400 Train Loss: 0.35263767242431643\n",
            "Epoch: 500 Train Loss: 0.34834235459566115\n",
            "Epoch: 600 Train Loss: 0.3291810601949692\n",
            "Epoch: 700 Train Loss: 0.3424492970108986\n",
            "Epoch: 800 Train Loss: 0.3304730996489525\n",
            "Epoch: 900 Train Loss: 0.34369952976703644\n",
            "Epoch: 1000 Train Loss: 0.32376574724912643\n",
            "Epoch: 1100 Train Loss: 0.33083646893501284\n",
            "Epoch: 1200 Train Loss: 0.3245365709066391\n",
            "Epoch: 1300 Train Loss: 0.323319086432457\n",
            "Epoch: 1400 Train Loss: 0.31863618791103365\n",
            "Epoch: 1500 Train Loss: 0.295289670675993\n",
            "Epoch: 1600 Train Loss: 0.31735763475298884\n",
            "Epoch: 1700 Train Loss: 0.3059804379940033\n",
            "Epoch: 1800 Train Loss: 0.31012887358665464\n",
            "Epoch: 1900 Train Loss: 0.29451688975095747\n",
            "Epoch: 2000 Train Loss: 0.30268605798482895\n",
            "Epoch: 2100 Train Loss: 0.2940620809793472\n",
            "Epoch: 2200 Train Loss: 0.2945985645055771\n",
            "Epoch: 2300 Train Loss: 0.3054888390004635\n",
            "Epoch: 2400 Train Loss: 0.3022800959646702\n",
            "Epoch: 2500 Train Loss: 0.28705357685685157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_ddpm(model, shape, betas, device, returned_t=None):\n",
        "    model.eval()\n",
        "    T = len(betas)\n",
        "    alphas = 1. - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0).to(device)\n",
        "    alphas_cumprod_prev = torch.cat([torch.tensor([1.], device=device), alphas_cumprod[:-1]])\n",
        "\n",
        "    eps = 1e-5\n",
        "    x_t = torch.randn(shape, device=device)\n",
        "\n",
        "    to_return = []\n",
        "    for t in reversed(range(T)):\n",
        "        t_tensor = torch.full((shape[0],), t, device=device).long()\n",
        "\n",
        "        beta_t = betas[t].to(device)\n",
        "        alpha_t = alphas[t].to(device)\n",
        "\n",
        "        sqrt_one_minus_ac = torch.sqrt(1 - alphas_cumprod[t] + eps)\n",
        "        sqrt_recip_alpha = torch.sqrt(1. / (alpha_t + eps))\n",
        "\n",
        "        eps_theta = model(x_t, t_tensor)\n",
        "\n",
        "        model_mean = sqrt_recip_alpha * (x_t - beta_t / sqrt_one_minus_ac * eps_theta)\n",
        "\n",
        "        if t > 0:\n",
        "            noise = torch.randn_like(x_t)\n",
        "            posterior_var = beta_t * (1 - alphas_cumprod_prev[t]) / (1 - alphas_cumprod[t] + eps)\n",
        "            x_t = model_mean + torch.sqrt(posterior_var + eps) * noise\n",
        "        else:\n",
        "            x_t = model_mean\n",
        "\n",
        "        if returned_t and t in returned_t:\n",
        "          to_return.append(x_t)\n",
        "\n",
        "    to_return.append(x_t)\n",
        "\n",
        "    return to_return"
      ],
      "metadata": {
        "id": "sqx-RmlQTUwv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "betas, alphas = cosine_beta_schedule(1000)\n",
        "betas = betas.to(device)\n",
        "preds = sample_ddpm(model, (1500, 2), betas, device, returned_t=[100*i for i in range(1, 11)])"
      ],
      "metadata": {
        "id": "0SLGH4ZtW3c0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "def animate_2d_samples(sampled_steps, interval=200, save_path=\"ddpm_evolution.gif\"):\n",
        "    fig, ax = plt.subplots()\n",
        "    scat = ax.scatter([], [], s=10)\n",
        "\n",
        "    def init():\n",
        "        ax.set_xlim(-5, 5)\n",
        "        ax.set_ylim(-5, 5)\n",
        "        return scat,\n",
        "\n",
        "    def update(frame):\n",
        "        data = sampled_steps[frame].detach().cpu()  # [N, 2]\n",
        "        scat.set_offsets(data.cpu().numpy())\n",
        "        ax.set_title(f\"Timestep {frame * 100}\")\n",
        "        return scat,\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, update, frames=len(sampled_steps), init_func=init, blit=True, interval=interval)\n",
        "    ani.save(save_path, writer='pillow')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "3Oyu4tesWqvf"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animate_2d_samples(preds, interval=500)"
      ],
      "metadata": {
        "id": "395E1kaxW0up"
      },
      "execution_count": 81,
      "outputs": []
    }
  ]
}